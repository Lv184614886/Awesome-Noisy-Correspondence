#### 2025

- `[2025 ICLR]` **Discovering Clone Negatives via Adaptive Contrastive Learning for Image-Text Matching**  
*Renjie Pan, Jihao Dong, Hua Yang*    
[[paper]](https://openreview.net/pdf?id=My9MBsO41H)

- `[2025 TIP]` **Disentangled Noisy Correspondence Learning**  
*Zhuohang Dang, Minnan Luo, Jihong Wang, Chengyou Jia, Haochen Han, Herun Wan, Guang Dai, Xiaojun Chang, Jingdong Wang*    
[[paper]](https://arxiv.org/pdf/2408.05503)

- `[2025 CVPR]` **ReCon: Enhancing True Correspondence Discrimination through Relation Consistency for Robust Noisy Correspondence Learning**  
*Quanxing Zha, Xin Liu, Shu-Juan Peng, Yiu-ming Cheung, Xing Xu, Nannan Wang*  
[[paper]](https://arxiv.org/pdf/2502.19962)
[[code]](https://github.com/qxzha/ReCon)

- `[2025 AAAI]` **TSVC: Tripartite Learning with Semantic Variation Consistency for Robust Image-Text Retrieval**  
*Shuai Lyu, Zijing Tian, Zhonghong Ou, Yifan Zhu, Xiao Zhang, Qiankun Ha, Haoran Luo, Meina Song*    
[[paper]](https://arxiv.org/pdf/2501.10935)

- `[2025 AAAI]` **Noisy Correspondence Rectifcation via Asymmetric Similarity Learning**  
*Yunbo Wang, YuJie Wu, Zhien Dai, Can Tian, Jun Long, Jianhai Chen*    
[[paper]](https://ojs.aaai.org/index.php/AAAI/article/view/35439)

#### 2024

- `[2024 Arxiv]` **Robust Noisy Correspondence Learning via Self-Drop and Dual-Weight**  
*Fan Liu, Chenwei Dong, Chuanyi Zhang, Hualiang Zhou, Jun Zhou*    
[[paper]](https://arxiv.org/abs/2412.06172)

- `[2024 Arxiv]` **One-step Noisy Label Mitigation**  
*Hao Li, Jiayang Gu, Jingkuan Song, An Zhang, Lianli Gao*    
[[paper]](https://arxiv.org/pdf/2410.01944)
[[code]](https://github.com/leolee99/OSA)

- `[2024 TOMM]`  **Bias Mitigation and Representation Optimization for Noise-Robust Cross-modal Retrieval**  
*Yu Liu, Haipeng Chen, Guihe Qin, Jincai Song, Xun Yang*  
[[paper]](https://dl.acm.org/doi/pdf/10.1145/3700596)

- `[2024 MICCAI]` **Medical Cross-Modal Prompt Hashing with Robust Noisy Correspondence Learning**  
*Yishu Liu, Zhongqi Wu, Bingzhi Chen, Zheng Zhang, Guangming Lu*  
[[paper]](https://papers.miccai.org/miccai-2024/paper/2150_paper.pdf)

- `[2024 ACMMM]` **Partially Aligned Cross-modal Retrieval via Optimal Transport-based Prototype Alignment Learning**  
*Junsheng Wang, Tiantian Gong, Yan Yan*   
[[paper]](https://dl.acm.org/doi/10.1145/3664647.3681577)

- `[2024 ACMMM]` **$\text{PC}^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal Retrieval**  
*Yue Duan, Zhangxuan Gu, Zhenzhe Ying, Lei Qi, Changhua Meng, Yinghuan Shi*   
[[paper]](https://arxiv.org/abs/2408.01349)
[[code]](https://github.com/alipay/PC2-NoiseofWeb)


- `[2024 SIGIR]` **UGNCL: Uncertainty-Guided Noisy Correspondence Learning for Efficient Cross-Modal Matching**  
*Quanxing Zha, Xin Liu, Yiu-ming Cheung, Xing Xu, Nannan Wang, Jianjia Cao*   
[[paper]](https://dl.acm.org/doi/abs/10.1145/3626772.3657806)
[[code]](https://github.com/qxzha/UGNCL)


- `[2024 IJCV]` **⭐Learning with Noisy Correspondence**  
*Zhenyu Huang, Peng Hu, Guocheng Niu, Xinyan Xiao, Jiancheng Lv, Xi Peng*   
[[paper]](https://link.springer.com/article/10.1007/s11263-024-02064-0)

- `[2024 TOIS]` **Breaking Through the Noisy Correspondence: A Robust Model for Image-Text Matching**   
*Haitao Shi, Meng Liu, Xiaoxuan Mu, Xuemeng Song, Yupeng Hu, Liqiang Nie*  
[[paper]](https://dl.acm.org/doi/abs/10.1145/3662732) 

- `[2024 ICASSP]` **NAC: Mitigating Noisy Correspondence in Cross-Modal Matching Via Neighbor Auxiliary Corrector**  
*Yuqing Li, Haoming Huang, Jian Xu, Shao-Lun Huang*  
[[paper]](https://ieeexplore.ieee.org/abstract/document/10448059) 


- `[2024 CVPR]` **Robust Noisy Correspondence Learning with Equivariant Similarity Consistency**  
*Yuchen Yang, Likai Wang, Erkun Yang, Cheng Deng*  
[[paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Robust_Noisy_Correspondence_Learning_with_Equivariant_Similarity_Consistency_CVPR_2024_paper.pdf)


- `[2024 CVPR]` **Mitigating Noisy Correspondence by Geometrical Structure Consistency Learning**  
*Zihua Zhao, Mengxi Chen, Tianjie Dai, Jiangchao Yao, Bo han, Ya Zhang, Yanfeng Wang*    
[[paper]](https://arxiv.org/abs/2405.16996)
[[code]](https://github.com/MediaBrain-SJTU/GSC)

- `[2024 CVPR]` **Learning to Rematch Mismatched Pairs for Robust Cross-Modal Retrieval**  
*Haochen Han, Qinghua Zheng, Guang Dai, Minnan Luo, Jingdong Wang*  
[[paper]](https://arxiv.org/html/2403.05105v1)
[[code]](https://github.com/hhc1997/L2RM)

- `[2024 CVPR]` **Robust Noisy Correspondence Learning with Equivariant Similarity Consistency**  
*Yuchen Yang, Erkun Yang, Likai Wang, Cheng Deng*  
 [[paper]](https://cvpr.thecvf.com/Conferences/2024/AcceptedPapers)

- `[2024 Arxiv]` **REPAIR: Rank Correlation and Noisy Pair Half-replacing with Memory for Noisy Correspondence**  
*Ruochen Zheng, Jiahao Hong, Changxin Gao, Nong Sang*  
[[paper]](https://arxiv.org/abs/2403.08224) 

- `[2024 TIP]` **⭐Cross-modal Retrieval with Noisy Correspondence via Consistency Refining and Mining**  
*Xinran Ma#, Mouxing Yang#, Yunfan Li, Peng Hu, Jiancheng Lv, Xi Peng*  
[[paper]](http://pengxi.me/wp-content/uploads/2024/03/Cross-modal-Retrieval-with-Noisy-Correspondence-via-Consistency-Refining-and-Mining.pdf)
[[code]](https://github.com/XLearning-SCU/2024-TIP-CREAM)

- `[2024 AAAI]` **Noisy Correspondence Learning with Self-Reinforcing Errors Mitigation**  
*Zhuohang Dang, Minnan Luo, Chengyou Jia, Guang Dai, Xiaojun Chang, Jingdong Wang*  
[[paper]](https://arxiv.org/pdf/2312.16478.pdf)

- `[2024 AAAI]` **Negative Pre-aware for Noisy Cross-modal Matching**  
*Xu Zhang, Hao Li, Mang Ye*  
[[paper]](https://arxiv.org/pdf/2312.05777.pdf)
[[code]](https://github.com/ZhangXu0963/NPC)

#### 2023

- `[2023 NeurIPS]` **⭐Cross-modal Active Complementary Learning with Self-refining Correspondence**  
*Yang Qin and Yuan Sun and Dezhong Peng and Joey Tianyi Zhou and Xi Peng and Peng Hu*  
[[paper]](https://openreview.net/pdf?id=UBBeUjTja8)
[[code]](https://github.com/QinYang79/CRCL)

- `[2023 TPAMI]` **⭐Cross-Modal Retrieval with Partially Mismatched Pairs**  
*Peng Hu, Zhenyu Huang, Dezhong Peng, Xu Wang, Xi Peng*  
[[paper]](http://pengxi.me/wp-content/uploads/2023/03/Cross-Modal_Retrieval_with_Partially_Mismatched_Pairs.pdf)
[[code]](https://github.com/penghu-cs/RCL)

- `[2023 TMM]` **Integrating Language Guidance Into Image-Text Matching for Correcting False Negatives**  
*Zheng Li, Caili Guo, IEEE, Zerun Feng, Jenq-Neng Hwang, Zhongtian Du*  
[[paper]](https://ieeexplore.ieee.org/abstract/document/10081045)

- `[2023 TMM]` **Learning From Noisy Correspondence With Tri-Partition for Cross-Modal Matching**  
*Feng, Zerun and Zeng, Zhimin and Guo, Caili and Li, Zheng and Hu, Lin*  
[[paper]](https://ieeexplore.ieee.org/abstract/document/10258402)

- `[2023 CVPR]` **BiCro: Noisy Correspondence Rectification for Multi-modality Data via Bi-directional Cross-modal Similarity Consistency**  
*Shuo Yang, Zhapan XU, Kai Wang, Yang You, Hongxun Yao, Tongliang Liu, Min Xu*  
[[paper]](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_BiCro_Noisy_Correspondence_Rectification_for_Multi-Modality_Data_via_Bi-Directional_Cross-Modal_CVPR_2023_paper.html)
[[code]](https://github.com/xu5zhao/BiCro)


- `[2023 CVPR]` **MSCN: Noisy Correspondence Learning with Meta Similarity Correction**  
*Han, Haochen and Miao, Kaiyao and Zheng, Qinghua and Luo, Minnan*  
[[paper]](https://openaccess.thecvf.com/content/CVPR2023/html/Han_Noisy_Correspondence_Learning_With_Meta_Similarity_Correction_CVPR_2023_paper.html)
[[code]](https://github.com/hhc1997/MSCN)

#### 2022

- `[2022 ACMMM]` **⭐Deep Evidential Learning with Noisy Correspondence for Cross-Modal Retrieval**  
*Qin, Yang and Peng, Dezhong and Peng, Xi and Wang, Xu and Hu, Peng*  
[[paper]](https://dl.acm.org/doi/abs/10.1145/3503161.3547922)
[[code]](https://github.com/QinYang79/DECL)

#### 2021
- `[2021 NeurIPS Oral]` **⭐Learning with Noisy Correspondence for Cross-modal Matching**  
*Huang, Zhenyu and Niu, Guocheng and Liu, Xiao and Ding, Wenbiao and Xiao, Xinyan and Wu, Hua and Peng, Xi*  
[[paper]](https://proceedings.neurips.cc/paper/2021/file/f5e62af885293cf4d511ceef31e61c80-Paper.pdf)
[[code]](https://github.com/XLearning-SCU/2021-NeurIPS-NCR)

##  Vision-Language Pre-training
- `[2024 TPAMI]` **⭐Noise-robust Vision-language Pre-training with Positive-negative Learning**  
Zhenyu Huang#, Mouxing Yang#, Xinyan Xiao, Peng Hu, Xi Peng*  
[[paper]](https://ieeexplore.ieee.org/document/10684058)
[[code]](https://github.com/XLearning-SCU/2024-TPAMI-NEVER)

- `[2023 AAAI]` **NLIP: Noise-Robust Language-Image Pre-training**   
*Runhui Huang, Yanxin Long, Jianhua Han, Hang Xu, Xiwen Liang, Chunjing Xu, Xiaodan Liang*  
[[paper]](https://ojs.aaai.org/index.php/AAAI/article/view/25172)

- `[2022 CVPR]` **Robust Cross-Modal Representation Learning with Progressive Self-Distillation**  
*Andonian, Alex and Chen, Shixing and Hamid, Raffay*  
[[paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Andonian_Robust_Cross-Modal_Representation_Learning_With_Progressive_Self-Distillation_CVPR_2022_paper.pdf)

- `[2022 ICML]` **Blip: Bootstrapping Language-image Pre-training for Unified Vision-language Understanding and Generation**  
Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven*  
[[paper]](https://proceedings.mlr.press/v162/li22n/li22n.pdf)
[[code]](https://github.com/salesforce/BLIP)

- `[2021 NeurIPS Spotlight]` **Align before Fuse: Vision and Language Representation Learning with Momentum Distillation**  
*Junnan Li, Ramprasaath Selvaraju, Akhilesh Gotmare, Shafiq Joty, Caiming Xiong, Steven Chu Hong Hoi*  
[[paper]](https://proceedings.neurips.cc/paper_files/paper/2021/file/505259756244493872b7709a8a01b536-Paper.pdf)
[[code]](https://github.com/salesforce/ALBEF)

